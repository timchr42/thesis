\chapter{Discussion}
\label{chap:discussion}

% Critically analyze results:
% 
% - How effectively does the approach meet the HyTrack goals?
% 
% - What are the trade-offs (complexity, compatibility, user transparency)?
%
% - How could Android or browsers adopt this natively?
%
% - Limitations (e.g., malicious developers, non-cookie tracking).

% Discussion -> Why it matters, what it implies, what the limitations are, and how it connects to broader context

In this chapter, we discuss the broader implications of the results presented in the previous chapter, focusing on how our findings affect developer workflows (\autoref{sec:dev-empowerment}), compatibility with existing browser mechanisms (\autoref{sec:compatibility}), usability considerations (\autoref{sec:usability-adoption}), and performance aspects of the proposed framework (\autoref{sec:performance-overhead}).

\section{Developer Empowerment and Transparency}
\label{sec:dev-empowerment}

Beyond mitigating HyTrack's tracking capabilities, our approach introduces a new dimension of developer transparency and control.
Developers can explicitly define which domains and cookies should remain private, preventing accidental leakage of sensitive identifiers to third parties.
This transforms the browser from a monolithic storage manager into a configurable privacy mediator, empowering developers to reason about and enforce their privacy boundaries.

The ability to read and modify issued capability tokens directly from within the app also enables explicit auditing and debugging of cookie behavior, which may be particularly beneficial during development and testing.
This developer-centric perspective distinguishes our approach from existing browser-level isolation mechanisms, which operate opaquely and offer little insight into how cookies are handled internally.

\section{Compatibility with Existing Mechanisms}
\label{sec:compatibility}

Our mitigation mechanism is designed to coexist with, and complement, existing browser-level cookie isolation techniques such as CHIPS~\cite{googlechips}.
If a capability authorizes access to the shared cookie jar, cookies are stored using Firefox’s native partitioning logic.
Otherwise, storage occurs solely in the app's local context.
This hybrid model preserves the benefits of CHIPS while adding a developer-driven control layer on top, allowing flexible yet secure isolation boundaries.
Such compatibility is critical for deployability, as it allows gradual integration into browsers without requiring the removal or modification of existing standards.

\section{Usability and Adoption Considerations}
\label{sec:usability-adoption}

The usability and adoption of Byetrack depend largely on how the necessary platform changes are handled.
If Android were to natively expose the caller UID in Intents --- as demonstrated in our prototype implementation ---, our mitigation introduces virtually no additional friction for developers or end-users.
In this scenario, developers only need to include a policy file and depend on our modified AndroidX Browser library, as all remaining enforcement occurs transparently in the browser.
No new APIs, permissions, or configuration steps are required.

This low integration effort enables incremental adoption: developers can choose to isolate only selected domains or even specific cookies without modifying their existing codebase. End-users benefit from stronger privacy guarantees without any visible change in app or browser behavior.

Under such platform support, the framework integrates naturally into the existing Android ecosystem.
A future release of the AndroidX Browser library could embed this logic directly, allowing widespread deployment without imposing additional work on developers.

If, however, Android does not provide the caller UID in Intents by default, developers would need to build against a modified SDK to enable capability issuance.
This requirement raises the barrier to adoption and may limit practical deployment.
Nonetheless, even in this case, the developer-side integration remains minimal once the platform support is present.

A minor usability limitation concerns app updates: when a policy is retransmitted and new tokens are issued, cookies previously stored in an app's isolated jar are discarded.

\section{Performance Overhead}
\label{sec:performance-overhead}

\begin{table}[h]
\centering
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{lcc}
\toprule
Scope & Wildcard & Predefined \\ 
\midrule
Private & highest & low-high \\
Public & lowest & low \\
\bottomrule
\end{tabular}
\caption{Priority levels of Byetrack capability tokens based on their scope and definition type.}
\label{tab:token-priority}
\end{table}

Letting the browser merely sign the tokens before transmitting them to the application does not provide sufficient security (\autoref{sec:threat_model}).
Therefore, our design requires the browser to both encrypt and decrypt capability tokens during issuance and validation.
This approach ensures end-to-end integrity and confidentiality but inevitably introduces performance overhead due to the additional cryptographic operations.
The magnitude of this overhead depends primarily on the number of cookies processed, the type of capability token employed, and the defined access scope (\autoref{tab:token-priority}).
By storing the tokens by domain in the app, we already minimize the number of tokens needed to be processed for both cookie reception and transmission.

\paragraph{Public wildcard.}
If a domain is classified as trusted, the browser issues a single public wildcard token covering all cookies associated with that domain.
As a result, the performance overhead is minimal: only one token must be decrypted and verified, regardless of the number of cookies.
All cookies share the same access rights to the global cookie jar and therefore follow the browser’s native storage logic without additional isolation steps.

\paragraph{Private wildcard.}
If a domain is deemed untrusted, the browser issues one private wildcard token for all cookies originating from that domain.
Again, only a single token must be decrypted for verification.
However, unlike the public case, all cookies are stored in the app's isolated jar.
This increases overhead as the number of cookies grows, since each cookie must be individually wrapped in a capability and subsequently signed and encrypted by the browser for local storage.

\paragraph{Public predefined.}
If individual cookies are explicitly registered as public in the policy, the browser generates separate predefined tokens for each cookie for access to the shared jar.
This leads to higher overhead during issuance, as each cookie requires its own token to be signed and encrypted.
During verification, each predefined token must also be decrypted and validated individually.
Nevertheless, since these cookies remain in the shared jar, the recurring runtime cost for subsequent accesses is relatively low.

\paragraph{Private predefined.}
For domains in the policy declared as private, where individual cookies are defined explicitly, the browser issues one private predefined token per cookie.
This configuration incurs the highest overall cost: every token must be decrypted and validated separately, and each cookie must be re-encrypted and stored in the app's private jar.
While providing the strongest isolation guarantees, this mode also introduces the greatest cryptographic overhead.

\section{Limitations}

While our mitigation addresses HyTrack's cross-app tracking channel effectively, several limitations remain.
First, the system relies on correctly defined policies; incomplete or misconfigured policies may lead to under- or over-isolation, affecting usability or privacy respectively.
Second, integrating the approach on the application side is straightforward by just replacing the browser library dependency, but extending the approach to other browsers would require their cooperation and modification, as browsers use different engines and therefore might have different cookie management mechanisms.
Despite this, the changes would still be relatively small, as most modern browsers are Chromium-based and share similar architectures.

Moreover, our threat model assumes non-malicious developers.
If an app developer intentionally collaborates with a tracking library or exfiltrates tokens, the current design cannot prevent data leakage.
Similarly, by storing the capability tokens encrypted in the app's private storage, we can prevent a malicious third-party library from reading and modifying them easily, but we cannot prevent the library from deleting the tokens themselves, as both the app and the library are executed under the same UID and thus inherit the host app's privileges.
Nonetheless, such deletion would only result in loss of session continuity rather than cross-app tracking.

\section{Summary}

Overall, the discussion highlights that capability-based, policy-driven cookie isolation offers a practical path to mitigating cross-app tracking while maintaining the flexibility required for legitimate web integrations.
The results confirm that it is possible to reconcile privacy and usability within the app–browser ecosystem, providing developers with meaningful control over cookie behavior.
